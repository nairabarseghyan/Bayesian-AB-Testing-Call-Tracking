{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to bayesian_ab_testing documentation How to install Note: python version 3.11 or above required pip install bayesian_ab_testing Project layout bayesian_ab_testing api data_preparation models","title":"Welcome to bayesian_ab_testing documentation"},{"location":"#welcome-to-bayesian_ab_testing-documentation","text":"","title":"Welcome to bayesian_ab_testing documentation"},{"location":"#how-to-install","text":"Note: python version 3.11 or above required pip install bayesian_ab_testing","title":"How to install"},{"location":"#project-layout","text":"bayesian_ab_testing api data_preparation models","title":"Project layout"},{"location":"api/","text":"bayesian_ab_testing.api This module contains an example API ready to go. get_arm handles GET at /arm Gets arm information, or multiple if id = -1 Parameters: id ( int , default: -1 ) \u2013 id of arm. Defaults to -1. Returns: dict ( dict ) \u2013 arm info Source code in bayesian_ab_testing\\api\\api.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @app . get ( \"/arm\" ) async def get_arm ( id : int = - 1 ) -> dict : \"\"\"Gets arm information, or multiple if id = -1 Args: id (int, optional): id of arm. Defaults to -1. Returns: dict: arm info \"\"\" with SqlHandler ( \"DimArm\" ) as dim_arm : if id < 0 : res = dim_arm . from_sql_to_pandas () . to_dict () return { k :{ id : v [ id ]} if id < len ( v ) and id >= 0 else v for k , v in res . items ()} if id is not None else res else : res = dim_arm . select_one ( id ) return res add_arm handles POST at /arm Adds an arm Parameters: customer_id ( int ) \u2013 identifier type ( str ) \u2013 type reward ( float ) \u2013 Amount of reward per trigger Returns: dict ( dict ) \u2013 Arm as a dict Source code in bayesian_ab_testing\\api\\api.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @app . post ( \"/arm\" ) async def add_arm ( customer_id : int , type : str , reward : float ) -> dict : \"\"\"Adds an arm Args: customer_id (int): identifier type (str): type reward (float): Amount of reward per trigger Returns: dict: Arm as a dict \"\"\" id = SqlHandler ( \"DimArm\" ) . get_next_id () ThompsonArm ( id , cnxn , type = type , customer_id = customer_id , reward = reward ) return { \"arm_id\" : id , \"type\" : type , \"reward\" : reward , \"active\" : 1 } mod_arm handles PUT at /arm/type Modifies the type of the arm Parameters: id ( int ) \u2013 arm identifier type ( Union [ str , None] ) \u2013 type Returns: str ( str ) \u2013 \"ok\" if ok Source code in bayesian_ab_testing\\api\\api.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 @app . put ( \"/arm/type\" ) async def mod_arm ( id : int , type : Union [ str , None ]) -> str : \"\"\"Modifies the type of the arm Args: id (int): arm identifier type (Union[str, None]): type Returns: str: \"ok\" if ok \"\"\" try : ThompsonArm ( id ) . change_type ( type ) except ValueError as e : return \"ValueError: \" + str ( e ) return \"ok\" toggle_arm handles PUT at /arm Turns an arm on/off Parameters: id ( int ) \u2013 arm id Returns: str ( str ) \u2013 ok or error message Source code in bayesian_ab_testing\\api\\api.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 @app . put ( \"/arm\" ) async def toggle_arm ( id : int ) -> str : \"\"\"Turns an arm on/off Args: id (int): arm id Returns: str: ok or error message \"\"\" try : ThompsonArm ( id , cnxn ) . toggle_active () except ValueError as e : logging . error ( e ) return \"ValueError: \" + str ( e ) return \"ok\" sample_arm handles GET at /sample Samples from all arms and choses the best one Parameters: customer_id ( int ) \u2013 Customer id information ( Union [ str , None] ) \u2013 Additional client data Returns: dict ( dict ) \u2013 a serve object as a dict Source code in bayesian_ab_testing\\api\\api.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 @app . get ( \"/sample\" ) async def sample_arm ( customer_id : int , information : Union [ str , None ]) -> dict : \"\"\"Samples from all arms and choses the best one Args: customer_id (int): Customer id information (Union[str, None]): Additional client data Returns: dict: a serve object as a dict \"\"\" algo = ThompsonAlgo ( cnxn , customer_id ) serve = algo . get_best_arm ( information ) return serve log_result handles PUT at /sample Logs a trigger Parameters: customer_id ( int ) \u2013 Customer identifier arm_id ( int ) \u2013 Arm identifier serve_id ( int ) \u2013 Serve identifier Returns: str ( str ) \u2013 \"ok\" of ok Source code in bayesian_ab_testing\\api\\api.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 @app . put ( \"/sample\" ) async def log_result ( customer_id , arm_id , serve_id ) -> str : \"\"\"Logs a trigger Args: customer_id (int): Customer identifier arm_id (int): Arm identifier serve_id (int): Serve identifier Returns: str: \"ok\" of ok \"\"\" algo = ThompsonAlgo ( cnxn , customer_id ) [ arm for arm in algo . arms if arm . id == int ( arm_id )][ 0 ] . log_trigger ( serve_id ) return \"ok\" stats handles GET at /stats Summary statistics and state of an arm Parameters: arm_id ( int ) \u2013 arm identifier Returns: dict ( dict ) \u2013 Dict with aggregated values and state Source code in bayesian_ab_testing\\api\\api.py 148 149 150 151 152 153 154 155 156 157 158 159 160 @app . get ( \"/stats\" ) async def stats ( arm_id : int ) -> dict : \"\"\"Summary statistics and state of an arm Args: arm_id (int): arm identifier Returns: dict: Dict with aggregated values and state \"\"\" agr = SqlHandler ( \"AggregateResult\" ) res = agr . select_one ( arm_id ) return res add_client handles POST at /client Adds a client to the db Parameters: name ( str ) \u2013 Name location ( str ) \u2013 location contact ( str ) \u2013 contact info Returns: dict ( dict ) \u2013 customer as a dict Source code in bayesian_ab_testing\\api\\api.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 @app . post ( \"/client\" ) async def add_client ( name : str , location : str , contact : str ) -> dict : \"\"\"Adds a client to the db Args: name (str): Name location (str): location contact (str): contact info Returns: dict: customer as a dict \"\"\" cust = SqlHandler ( \"DimCustomer\" ) id = cust . get_next_id () cust_dict = dict ( customer_id = id , name = name , location = location , contact = contact ) cust . insert_one ( ** cust_dict ) return cust_dict","title":"bayesian_ab_testing.api"},{"location":"api/#bayesian_ab_testingapi","text":"This module contains an example API ready to go.","title":"bayesian_ab_testing.api"},{"location":"data_preparation/","text":"bayesian_ab_testing.data_preparation This module contains fake data generators that one can use to test the package. Object-relational mapper create_ORM Creates the sql tables by mapping objects to it Parameters: path ( str ) \u2013 path to sqlite db Source code in bayesian_ab_testing\\data_preparation\\schema.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def create_ORM ( path ): \"\"\"Creates the sql tables by mapping objects to it Args: path (str): path to sqlite db \"\"\" engine = create_engine ( f 'sqlite:/// { path } ' ) Base = declarative_base () class DimDate ( Base ): __tablename__ = \"DimDate\" date_id = Column ( Integer , primary_key = True ) date = Column ( DateTime ) day = Column ( Integer ) month = Column ( Integer ) quarter = Column ( Integer ) year = Column ( Integer ) class DimArm ( Base ): __tablename__ = \"DimArm\" arm_id = Column ( Integer , primary_key = True ) type = Column ( String ) reward = Column ( Float ) active = Column ( Boolean ) class DimCustomer ( Base ): __tablename__ = \"DimCustomer\" customer_id = Column ( Integer , primary_key = True ) name = Column ( String ) location = Column ( String ) contact = Column ( String ) class Serve ( Base ): __tablename__ = \"Serve\" serve_id = Column ( Integer , primary_key = True ) date_id = Column ( Integer , ForeignKey ( 'DimDate.date_id' )) customer_id = Column ( Integer , ForeignKey ( 'DimCustomer.customer_id' )) arm_id = Column ( Integer , ForeignKey ( 'DimArm.arm_id' )) information = Column ( String ) result = Column ( Boolean , nullable = True ) class AggregateResult ( Base ): __tablename__ = \"AggregateResult\" arm_id = Column ( Integer , primary_key = True ) customer_id = Column ( Integer ) n_triggered = Column ( Integer ) n_served = Column ( Integer ) a = Column ( Float ) b = Column ( Float ) average_reward = Column ( Float ) Base . metadata . create_all ( engine ) del Base del engine Data generation generate_arm Generates an arm Parameters: arm_id ( int ) \u2013 arm_id Returns: dict ( dict ) \u2013 arm Source code in bayesian_ab_testing\\data_preparation\\data_generator.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def generate_arm ( arm_id ) -> dict : \"\"\"Generates an arm Args: arm_id (int): arm_id Returns: dict: arm \"\"\" return { \"arm_id\" : arm_id , \"type\" : fake . word (), \"reward\" : np . random . randint ( 1 , 15 ), \"active\" : np . random . uniform () > 0.85 } generate_customer Generates a customer with random info Parameters: customer_id ( int ) \u2013 customer_id Returns: dict ( dict ) \u2013 customer Source code in bayesian_ab_testing\\data_preparation\\data_generator.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 def generate_customer ( customer_id ) -> dict : \"\"\"Generates a customer with random info Args: customer_id (int): customer_id Returns: dict: customer \"\"\" return { \"customer_id\" : customer_id , \"name\" : fake . name (), \"location\" : fake . street_address (), \"contact\" : fake . phone_number () } generate_date Generates a random date in 2023 Parameters: date_id ( int ) \u2013 date_id Returns: dict ( dict ) \u2013 date Source code in bayesian_ab_testing\\data_preparation\\data_generator.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def generate_date ( date_id ) -> dict : \"\"\"Generates a random date in 2023 Args: date_id (int): date_id Returns: dict: date \"\"\" # Generate a random date between a specific date range start_date = datetime ( 2023 , 1 , 1 ) end_date = datetime ( 2023 , 12 , 31 ) random_date = fake . date_time_between_dates ( start_date , end_date ) # Extract year, quarter, and month from the random date year = random_date . year quarter = ( random_date . month - 1 ) // 3 + 1 month = random_date . strftime ( '%m' ) day = random_date . strftime ( ' %d ' ) return { \"date_id\" : date_id , \"date\" : random_date . strftime ( \"%Y-%m- %d \" ), \"day\" : day , \"month\" : month , \"quarter\" : quarter , \"year\" : year } generate_serve Generates a serve with random info Parameters: serve_id ( int ) \u2013 serve_id date_id ( int ) \u2013 date_id customer_id ( int ) \u2013 customer_id arm_id ( int ) \u2013 arm_id p ( float ) \u2013 probability of success Returns: dict ( dict ) \u2013 serve Source code in bayesian_ab_testing\\data_preparation\\data_generator.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def generate_serve ( serve_id , date_id , customer_id , arm_id , p ) -> dict : \"\"\"Generates a serve with random info Args: serve_id (int): serve_id date_id (int): date_id customer_id (int): customer_id arm_id (int): arm_id p (float): probability of success Returns: dict: serve \"\"\" return { \"serve_id\" : serve_id , \"date_id\" : date_id , \"customer_id\" : customer_id , \"arm_id\" : arm_id , \"information\" : json . dumps ( fake . profile ()), \"result\" : np . random . uniform () >= p } SQL Handler SqlHandler Bases: ISQL_Etiquette Handles all interactions with the database Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 class SqlHandler ( ISQL_Etiquette ): \"\"\"Handles all interactions with the database\"\"\" def __init__ ( self , table_name : str ) -> None : \"\"\"Initializes the sql handler of the table `table_name` Args: table_name (str): Which table to tether the handler to \"\"\" super () . __init__ () self . cnxn = sqlite3 . connect ( db_path ) self . table_name = table_name cur = self . exec ( f 'SELECT l.name FROM pragma_table_info(\" { table_name } \") as l WHERE l.pk = 1;' ) self . pk = list ( cur )[ 0 ][ 0 ] def __enter__ ( self ): \"\"\"Interfaces python `with` syntax\"\"\" return self def __exit__ ( self , * args , ** kwargs ): \"\"\"Exits the python `with` scope\"\"\" self . close_cnxn () def close_cnxn ( self ) -> None : \"\"\"Close the connection gracefully\"\"\" logger . info ( 'commiting the changes' ) self . cnxn . commit () logger . debug ( 'closing connection' ) self . cnxn . close () logger . info ( 'the connection has been closed' ) def insert_one ( self , ** kwargs ) -> None : \"\"\"Insert a single row into the table\"\"\" query = f \"INSERT INTO { self . table_name } ( { ', ' . join ([ k for k in kwargs . keys ()]) } ) VALUES ( { ', ' . join ([ '?' ] * len ( kwargs )) } );\" logging . debug ( query , [ v for v in kwargs . values ()]) cur = self . exec ( query , [ v for v in kwargs . values ()]) logging . info ( \"insert_one: \" + str ( list ( cur ))) def get_table_columns ( self ) -> list : \"\"\"Gets a list of the column names that belong to the table\"\"\" cur = self . exec ( f \"PRAGMA table_info( { self . table_name } );\" ) columns = cur . fetchall () column_names = [ col [ 1 ] for col in columns ] logger . info ( f 'the list of columns: { column_names } ' ) return column_names def truncate_table ( self ) -> None : \"\"\"Deletes all rows of the table\"\"\" query = f \"delete from { self . table_name } where 1=1;\" logging . info ( f 'the { self . table_name } is being truncated' ) self . exec ( query ) def drop_table ( self ): \"\"\"Drops the table from the database\"\"\" query = f \"DROP TABLE IF EXISTS { self . table_name } ;\" logging . info ( query ) self . exec ( query ) logging . info ( f \"table ' { self . table_name } ' deleted.\" ) def insert_many ( self , df : pd . DataFrame ): \"\"\"Insert many values at once into the table Args: df (pd.DataFrame): data to insert \"\"\" df = df . replace ( np . nan , None ) df . rename ( columns = lambda x : x . lower (), inplace = True ) columns = list ( df . columns ) logger . info ( f 'BEFORE the column intersection: { columns } ' ) sql_column_names = [ i . lower () for i in self . get_table_columns ()] columns = list ( set ( columns ) & set ( sql_column_names )) logger . info ( f 'AFTER the column intersection: { columns } ' ) assert len ( df . columns ) == len ( sql_column_names ), \"Mismatch in columns between the dataframe and the sql table. \\n df.columns: \" + \\ \", \" . join ( df . columns ) + \" \\n sql columns: \" + \", \" . join ( sql_column_names ) ncolumns = list ( len ( columns ) * '?' ) data_to_insert = df . loc [:, columns ] values = [ tuple ( i ) for i in data_to_insert . values ] logger . info ( f 'the shape of the table which is going to be imported { data_to_insert . shape } ' ) if len ( columns ) > 1 : cols , params = ', ' . join ( columns ), ', ' . join ( ncolumns ) else : cols , params = columns , ncolumns logger . info ( f 'insert structure: colnames: { cols } params: { params } ' ) logger . info ( values [ 0 ]) query = f \"\"\"INSERT INTO { self . table_name } ( { cols } ) VALUES ( { params } );\"\"\" logger . info ( f 'QUERY: { query } ' ) cur = self . exec_many ( query , values ) try : for i in cur . messages : logger . info ( i ) except : pass logger . warning ( 'the data is loaded' ) def from_sql_to_pandas ( self , chunksize : int = 64 ) -> pd . DataFrame : \"\"\"Converts the table into a pandas dataframe and returns it, reads the table in `chnksize`-sized chunks Args: chunksize (int, optional): Number of rows per sql request. Defaults to 64. Returns: pd.DataFrame: data \"\"\" offset = 0 dfs = [] while True : query = f \"\"\" SELECT * FROM { self . table_name } LIMIT { chunksize } OFFSET { offset } \"\"\" data = pd . read_sql_query ( query , self . cnxn ) self . cnxn . commit () logger . info ( f 'the shape of the chunk: { data . shape } ' ) dfs . append ( data ) offset += chunksize if len ( dfs [ - 1 ]) < chunksize : logger . info ( 'loading the data from SQL is finished' ) logger . debug ( 'connection is closed' ) break df = pd . concat ( dfs ) return df def update_table ( self , set_values : dict , condition : str ): \"\"\"Updates some the values of some fields of some rows (based on the condition) Args: set_values (dict): which columns to assign which values condition (str): condition upon which to update \"\"\" if not set_values : logger . warning ( 'No values to update. Provide set_values.' ) return set_clause = ', ' . join ( f \" { col } = ?\" for col in set_values . keys ()) values = list ( set_values . values ()) query = f \"\"\" UPDATE { self . table_name } SET { set_clause } WHERE { condition } ; \"\"\" cur = self . exec ( query , values if hasattr ( values , \"__iter__\" ) else list ( values )) logger . info ( f \"Rows updated: { cur . rowcount } \" ) def update_one ( self , id : int , ** kwargs : dict ): \"\"\"Updates a single row in the table Args: id (int): row to update \"\"\" cond = self . pk + \" = \" + str ( id ) self . update_table ( kwargs , cond ) def select_one ( self , id : int , cols : list = []) -> dict : \"\"\"Selects only one row and returns it as a python dictionary Args: id (int): id of row cols (list, optional): Which columns to select. Selects all columns if the list is empty. Defaults to []. Returns: dict: row \"\"\" cond = self . pk + \" = ?\" query = f \"select { '*' if len ( cols ) == 0 else ', ' . join ( cols ) } from { self . table_name } where { cond } \" cur = self . exec ( query , ( id , )) return { k : v for k , v in zip ( self . get_table_columns () if len ( cols ) == 0 else cols , list ( cur )[ 0 ])} def get_next_id ( self ): \"\"\"Conveniently gets the increment of the previous id (used for creating a new entry)\"\"\" query = f \"select (max( { self . pk } ) + 1) from { self . table_name } ;\" cur = list ( self . exec ( query )) cur = cur [ 0 ] return 0 if cur is None else cur [ 0 ] if cur [ 0 ] is not None else 0 __enter__ () Interfaces python with syntax Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 39 40 41 def __enter__ ( self ): \"\"\"Interfaces python `with` syntax\"\"\" return self __exit__ ( * args , ** kwargs ) Exits the python with scope Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 44 45 46 47 def __exit__ ( self , * args , ** kwargs ): \"\"\"Exits the python `with` scope\"\"\" self . close_cnxn () __init__ ( table_name ) Initializes the sql handler of the table table_name Parameters: table_name ( str ) \u2013 Which table to tether the handler to Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 24 25 26 27 28 29 30 31 32 33 34 35 36 def __init__ ( self , table_name : str ) -> None : \"\"\"Initializes the sql handler of the table `table_name` Args: table_name (str): Which table to tether the handler to \"\"\" super () . __init__ () self . cnxn = sqlite3 . connect ( db_path ) self . table_name = table_name cur = self . exec ( f 'SELECT l.name FROM pragma_table_info(\" { table_name } \") as l WHERE l.pk = 1;' ) self . pk = list ( cur )[ 0 ][ 0 ] close_cnxn () Close the connection gracefully Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 50 51 52 53 54 55 56 57 def close_cnxn ( self ) -> None : \"\"\"Close the connection gracefully\"\"\" logger . info ( 'commiting the changes' ) self . cnxn . commit () logger . debug ( 'closing connection' ) self . cnxn . close () logger . info ( 'the connection has been closed' ) drop_table () Drops the table from the database Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 90 91 92 93 94 95 96 97 def drop_table ( self ): \"\"\"Drops the table from the database\"\"\" query = f \"DROP TABLE IF EXISTS { self . table_name } ;\" logging . info ( query ) self . exec ( query ) logging . info ( f \"table ' { self . table_name } ' deleted.\" ) from_sql_to_pandas ( chunksize = 64 ) Converts the table into a pandas dataframe and returns it, reads the table in chnksize -sized chunks Parameters: chunksize ( int , default: 64 ) \u2013 Number of rows per sql request. Defaults to 64. Returns: DataFrame \u2013 pd.DataFrame: data Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 def from_sql_to_pandas ( self , chunksize : int = 64 ) -> pd . DataFrame : \"\"\"Converts the table into a pandas dataframe and returns it, reads the table in `chnksize`-sized chunks Args: chunksize (int, optional): Number of rows per sql request. Defaults to 64. Returns: pd.DataFrame: data \"\"\" offset = 0 dfs = [] while True : query = f \"\"\" SELECT * FROM { self . table_name } LIMIT { chunksize } OFFSET { offset } \"\"\" data = pd . read_sql_query ( query , self . cnxn ) self . cnxn . commit () logger . info ( f 'the shape of the chunk: { data . shape } ' ) dfs . append ( data ) offset += chunksize if len ( dfs [ - 1 ]) < chunksize : logger . info ( 'loading the data from SQL is finished' ) logger . debug ( 'connection is closed' ) break df = pd . concat ( dfs ) return df get_next_id () Conveniently gets the increment of the previous id (used for creating a new entry) Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 241 242 243 244 245 246 247 248 def get_next_id ( self ): \"\"\"Conveniently gets the increment of the previous id (used for creating a new entry)\"\"\" query = f \"select (max( { self . pk } ) + 1) from { self . table_name } ;\" cur = list ( self . exec ( query )) cur = cur [ 0 ] return 0 if cur is None else cur [ 0 ] if cur [ 0 ] is not None else 0 get_table_columns () Gets a list of the column names that belong to the table Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 70 71 72 73 74 75 76 77 78 79 def get_table_columns ( self ) -> list : \"\"\"Gets a list of the column names that belong to the table\"\"\" cur = self . exec ( f \"PRAGMA table_info( { self . table_name } );\" ) columns = cur . fetchall () column_names = [ col [ 1 ] for col in columns ] logger . info ( f 'the list of columns: { column_names } ' ) return column_names insert_many ( df ) Insert many values at once into the table Parameters: df ( DataFrame ) \u2013 data to insert Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def insert_many ( self , df : pd . DataFrame ): \"\"\"Insert many values at once into the table Args: df (pd.DataFrame): data to insert \"\"\" df = df . replace ( np . nan , None ) df . rename ( columns = lambda x : x . lower (), inplace = True ) columns = list ( df . columns ) logger . info ( f 'BEFORE the column intersection: { columns } ' ) sql_column_names = [ i . lower () for i in self . get_table_columns ()] columns = list ( set ( columns ) & set ( sql_column_names )) logger . info ( f 'AFTER the column intersection: { columns } ' ) assert len ( df . columns ) == len ( sql_column_names ), \"Mismatch in columns between the dataframe and the sql table. \\n df.columns: \" + \\ \", \" . join ( df . columns ) + \" \\n sql columns: \" + \", \" . join ( sql_column_names ) ncolumns = list ( len ( columns ) * '?' ) data_to_insert = df . loc [:, columns ] values = [ tuple ( i ) for i in data_to_insert . values ] logger . info ( f 'the shape of the table which is going to be imported { data_to_insert . shape } ' ) if len ( columns ) > 1 : cols , params = ', ' . join ( columns ), ', ' . join ( ncolumns ) else : cols , params = columns , ncolumns logger . info ( f 'insert structure: colnames: { cols } params: { params } ' ) logger . info ( values [ 0 ]) query = f \"\"\"INSERT INTO { self . table_name } ( { cols } ) VALUES ( { params } );\"\"\" logger . info ( f 'QUERY: { query } ' ) cur = self . exec_many ( query , values ) try : for i in cur . messages : logger . info ( i ) except : pass logger . warning ( 'the data is loaded' ) insert_one ( ** kwargs ) Insert a single row into the table Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 60 61 62 63 64 65 66 67 def insert_one ( self , ** kwargs ) -> None : \"\"\"Insert a single row into the table\"\"\" query = f \"INSERT INTO { self . table_name } ( { ', ' . join ([ k for k in kwargs . keys ()]) } ) VALUES ( { ', ' . join ([ '?' ] * len ( kwargs )) } );\" logging . debug ( query , [ v for v in kwargs . values ()]) cur = self . exec ( query , [ v for v in kwargs . values ()]) logging . info ( \"insert_one: \" + str ( list ( cur ))) select_one ( id , cols = []) Selects only one row and returns it as a python dictionary Parameters: id ( int ) \u2013 id of row cols ( list , default: [] ) \u2013 Which columns to select. Selects all columns if the list is empty. Defaults to []. Returns: dict ( dict ) \u2013 row Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def select_one ( self , id : int , cols : list = []) -> dict : \"\"\"Selects only one row and returns it as a python dictionary Args: id (int): id of row cols (list, optional): Which columns to select. Selects all columns if the list is empty. Defaults to []. Returns: dict: row \"\"\" cond = self . pk + \" = ?\" query = f \"select { '*' if len ( cols ) == 0 else ', ' . join ( cols ) } from { self . table_name } where { cond } \" cur = self . exec ( query , ( id , )) return { k : v for k , v in zip ( self . get_table_columns () if len ( cols ) == 0 else cols , list ( cur )[ 0 ])} truncate_table () Deletes all rows of the table Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 82 83 84 85 86 87 def truncate_table ( self ) -> None : \"\"\"Deletes all rows of the table\"\"\" query = f \"delete from { self . table_name } where 1=1;\" logging . info ( f 'the { self . table_name } is being truncated' ) self . exec ( query ) update_one ( id , ** kwargs ) Updates a single row in the table Parameters: id ( int ) \u2013 row to update Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 212 213 214 215 216 217 218 219 220 def update_one ( self , id : int , ** kwargs : dict ): \"\"\"Updates a single row in the table Args: id (int): row to update \"\"\" cond = self . pk + \" = \" + str ( id ) self . update_table ( kwargs , cond ) update_table ( set_values , condition ) Updates some the values of some fields of some rows (based on the condition) Parameters: set_values ( dict ) \u2013 which columns to assign which values condition ( str ) \u2013 condition upon which to update Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def update_table ( self , set_values : dict , condition : str ): \"\"\"Updates some the values of some fields of some rows (based on the condition) Args: set_values (dict): which columns to assign which values condition (str): condition upon which to update \"\"\" if not set_values : logger . warning ( 'No values to update. Provide set_values.' ) return set_clause = ', ' . join ( f \" { col } = ?\" for col in set_values . keys ()) values = list ( set_values . values ()) query = f \"\"\" UPDATE { self . table_name } SET { set_clause } WHERE { condition } ; \"\"\" cur = self . exec ( query , values if hasattr ( values , \"__iter__\" ) else list ( values )) logger . info ( f \"Rows updated: { cur . rowcount } \" )","title":"bayesian_ab_testing.data_preparation"},{"location":"data_preparation/#bayesian_ab_testingdata_preparation","text":"This module contains fake data generators that one can use to test the package.","title":"bayesian_ab_testing.data_preparation"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.__enter__","text":"Interfaces python with syntax Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 39 40 41 def __enter__ ( self ): \"\"\"Interfaces python `with` syntax\"\"\" return self","title":"__enter__()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.__exit__","text":"Exits the python with scope Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 44 45 46 47 def __exit__ ( self , * args , ** kwargs ): \"\"\"Exits the python `with` scope\"\"\" self . close_cnxn ()","title":"__exit__()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.__init__","text":"Initializes the sql handler of the table table_name Parameters: table_name ( str ) \u2013 Which table to tether the handler to Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 24 25 26 27 28 29 30 31 32 33 34 35 36 def __init__ ( self , table_name : str ) -> None : \"\"\"Initializes the sql handler of the table `table_name` Args: table_name (str): Which table to tether the handler to \"\"\" super () . __init__ () self . cnxn = sqlite3 . connect ( db_path ) self . table_name = table_name cur = self . exec ( f 'SELECT l.name FROM pragma_table_info(\" { table_name } \") as l WHERE l.pk = 1;' ) self . pk = list ( cur )[ 0 ][ 0 ]","title":"__init__()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.close_cnxn","text":"Close the connection gracefully Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 50 51 52 53 54 55 56 57 def close_cnxn ( self ) -> None : \"\"\"Close the connection gracefully\"\"\" logger . info ( 'commiting the changes' ) self . cnxn . commit () logger . debug ( 'closing connection' ) self . cnxn . close () logger . info ( 'the connection has been closed' )","title":"close_cnxn()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.drop_table","text":"Drops the table from the database Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 90 91 92 93 94 95 96 97 def drop_table ( self ): \"\"\"Drops the table from the database\"\"\" query = f \"DROP TABLE IF EXISTS { self . table_name } ;\" logging . info ( query ) self . exec ( query ) logging . info ( f \"table ' { self . table_name } ' deleted.\" )","title":"drop_table()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.from_sql_to_pandas","text":"Converts the table into a pandas dataframe and returns it, reads the table in chnksize -sized chunks Parameters: chunksize ( int , default: 64 ) \u2013 Number of rows per sql request. Defaults to 64. Returns: DataFrame \u2013 pd.DataFrame: data Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 def from_sql_to_pandas ( self , chunksize : int = 64 ) -> pd . DataFrame : \"\"\"Converts the table into a pandas dataframe and returns it, reads the table in `chnksize`-sized chunks Args: chunksize (int, optional): Number of rows per sql request. Defaults to 64. Returns: pd.DataFrame: data \"\"\" offset = 0 dfs = [] while True : query = f \"\"\" SELECT * FROM { self . table_name } LIMIT { chunksize } OFFSET { offset } \"\"\" data = pd . read_sql_query ( query , self . cnxn ) self . cnxn . commit () logger . info ( f 'the shape of the chunk: { data . shape } ' ) dfs . append ( data ) offset += chunksize if len ( dfs [ - 1 ]) < chunksize : logger . info ( 'loading the data from SQL is finished' ) logger . debug ( 'connection is closed' ) break df = pd . concat ( dfs ) return df","title":"from_sql_to_pandas()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.get_next_id","text":"Conveniently gets the increment of the previous id (used for creating a new entry) Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 241 242 243 244 245 246 247 248 def get_next_id ( self ): \"\"\"Conveniently gets the increment of the previous id (used for creating a new entry)\"\"\" query = f \"select (max( { self . pk } ) + 1) from { self . table_name } ;\" cur = list ( self . exec ( query )) cur = cur [ 0 ] return 0 if cur is None else cur [ 0 ] if cur [ 0 ] is not None else 0","title":"get_next_id()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.get_table_columns","text":"Gets a list of the column names that belong to the table Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 70 71 72 73 74 75 76 77 78 79 def get_table_columns ( self ) -> list : \"\"\"Gets a list of the column names that belong to the table\"\"\" cur = self . exec ( f \"PRAGMA table_info( { self . table_name } );\" ) columns = cur . fetchall () column_names = [ col [ 1 ] for col in columns ] logger . info ( f 'the list of columns: { column_names } ' ) return column_names","title":"get_table_columns()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.insert_many","text":"Insert many values at once into the table Parameters: df ( DataFrame ) \u2013 data to insert Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 def insert_many ( self , df : pd . DataFrame ): \"\"\"Insert many values at once into the table Args: df (pd.DataFrame): data to insert \"\"\" df = df . replace ( np . nan , None ) df . rename ( columns = lambda x : x . lower (), inplace = True ) columns = list ( df . columns ) logger . info ( f 'BEFORE the column intersection: { columns } ' ) sql_column_names = [ i . lower () for i in self . get_table_columns ()] columns = list ( set ( columns ) & set ( sql_column_names )) logger . info ( f 'AFTER the column intersection: { columns } ' ) assert len ( df . columns ) == len ( sql_column_names ), \"Mismatch in columns between the dataframe and the sql table. \\n df.columns: \" + \\ \", \" . join ( df . columns ) + \" \\n sql columns: \" + \", \" . join ( sql_column_names ) ncolumns = list ( len ( columns ) * '?' ) data_to_insert = df . loc [:, columns ] values = [ tuple ( i ) for i in data_to_insert . values ] logger . info ( f 'the shape of the table which is going to be imported { data_to_insert . shape } ' ) if len ( columns ) > 1 : cols , params = ', ' . join ( columns ), ', ' . join ( ncolumns ) else : cols , params = columns , ncolumns logger . info ( f 'insert structure: colnames: { cols } params: { params } ' ) logger . info ( values [ 0 ]) query = f \"\"\"INSERT INTO { self . table_name } ( { cols } ) VALUES ( { params } );\"\"\" logger . info ( f 'QUERY: { query } ' ) cur = self . exec_many ( query , values ) try : for i in cur . messages : logger . info ( i ) except : pass logger . warning ( 'the data is loaded' )","title":"insert_many()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.insert_one","text":"Insert a single row into the table Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 60 61 62 63 64 65 66 67 def insert_one ( self , ** kwargs ) -> None : \"\"\"Insert a single row into the table\"\"\" query = f \"INSERT INTO { self . table_name } ( { ', ' . join ([ k for k in kwargs . keys ()]) } ) VALUES ( { ', ' . join ([ '?' ] * len ( kwargs )) } );\" logging . debug ( query , [ v for v in kwargs . values ()]) cur = self . exec ( query , [ v for v in kwargs . values ()]) logging . info ( \"insert_one: \" + str ( list ( cur )))","title":"insert_one()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.select_one","text":"Selects only one row and returns it as a python dictionary Parameters: id ( int ) \u2013 id of row cols ( list , default: [] ) \u2013 Which columns to select. Selects all columns if the list is empty. Defaults to []. Returns: dict ( dict ) \u2013 row Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def select_one ( self , id : int , cols : list = []) -> dict : \"\"\"Selects only one row and returns it as a python dictionary Args: id (int): id of row cols (list, optional): Which columns to select. Selects all columns if the list is empty. Defaults to []. Returns: dict: row \"\"\" cond = self . pk + \" = ?\" query = f \"select { '*' if len ( cols ) == 0 else ', ' . join ( cols ) } from { self . table_name } where { cond } \" cur = self . exec ( query , ( id , )) return { k : v for k , v in zip ( self . get_table_columns () if len ( cols ) == 0 else cols , list ( cur )[ 0 ])}","title":"select_one()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.truncate_table","text":"Deletes all rows of the table Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 82 83 84 85 86 87 def truncate_table ( self ) -> None : \"\"\"Deletes all rows of the table\"\"\" query = f \"delete from { self . table_name } where 1=1;\" logging . info ( f 'the { self . table_name } is being truncated' ) self . exec ( query )","title":"truncate_table()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.update_one","text":"Updates a single row in the table Parameters: id ( int ) \u2013 row to update Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 212 213 214 215 216 217 218 219 220 def update_one ( self , id : int , ** kwargs : dict ): \"\"\"Updates a single row in the table Args: id (int): row to update \"\"\" cond = self . pk + \" = \" + str ( id ) self . update_table ( kwargs , cond )","title":"update_one()"},{"location":"data_preparation/#bayesian_ab_testing.data_preparation.SqlHandler.update_table","text":"Updates some the values of some fields of some rows (based on the condition) Parameters: set_values ( dict ) \u2013 which columns to assign which values condition ( str ) \u2013 condition upon which to update Source code in bayesian_ab_testing\\data_preparation\\sql_interactions.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 def update_table ( self , set_values : dict , condition : str ): \"\"\"Updates some the values of some fields of some rows (based on the condition) Args: set_values (dict): which columns to assign which values condition (str): condition upon which to update \"\"\" if not set_values : logger . warning ( 'No values to update. Provide set_values.' ) return set_clause = ', ' . join ( f \" { col } = ?\" for col in set_values . keys ()) values = list ( set_values . values ()) query = f \"\"\" UPDATE { self . table_name } SET { set_clause } WHERE { condition } ; \"\"\" cur = self . exec ( query , values if hasattr ( values , \"__iter__\" ) else list ( values )) logger . info ( f \"Rows updated: { cur . rowcount } \" )","title":"update_table()"},{"location":"models/","text":"bayesian_ab_testing.models Thompson sampling with bernoulli reward TS_Bernoulli.ThompsonAlgo Bases: ISQL_Etiquette The sampling algorithm used for live A/B testing Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 class ThompsonAlgo ( ISQL_Etiquette ): \"\"\"The sampling algorithm used for live A/B testing\"\"\" def __init__ ( self , cnxn : sqlite3 . Connection , customer_id : int ): \"\"\"Constructor that initializes the thompson algorithm Args: cnxn (sqlite3.Connection): Connection to db customer_id (int): customer_id Raises: ValueError: The customer has no active arms \"\"\" self . cnxn = cnxn self . customer_id = customer_id arms = list ( self . exec ( \"select arm_id, type, reward, active from DimArm where arm_id in (select arm_id from AggregateResult where customer_id = ?)\" , ( customer_id ,) )) if len ([ i for i in arms if i [ - 1 ]]) == 0 : logging . error (( em := \"The customer has no active arms\" )) raise ValueError ( em ) self . arms = [ ThompsonArm ( arm_id , cnxn , type = type_ , reward = reward , active = active , customer_id = customer_id ) for arm_id , type_ , reward , active in arms ] def get_best_arm ( self , information : str = None ) -> dict : \"\"\"Samples the best arm Args: information (str, optional): Information provided by the customer to be stored without structure. Defaults to None. Returns: dict: serve \"\"\" j = np . argmax ([ arm . pull () for arm in self . arms ]) best_arm = self . arms [ j ] serve = best_arm . log_sampled ( information ) return serve __init__ ( cnxn , customer_id ) Constructor that initializes the thompson algorithm Parameters: cnxn ( Connection ) \u2013 Connection to db customer_id ( int ) \u2013 customer_id Raises: ValueError \u2013 The customer has no active arms Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def __init__ ( self , cnxn : sqlite3 . Connection , customer_id : int ): \"\"\"Constructor that initializes the thompson algorithm Args: cnxn (sqlite3.Connection): Connection to db customer_id (int): customer_id Raises: ValueError: The customer has no active arms \"\"\" self . cnxn = cnxn self . customer_id = customer_id arms = list ( self . exec ( \"select arm_id, type, reward, active from DimArm where arm_id in (select arm_id from AggregateResult where customer_id = ?)\" , ( customer_id ,) )) if len ([ i for i in arms if i [ - 1 ]]) == 0 : logging . error (( em := \"The customer has no active arms\" )) raise ValueError ( em ) self . arms = [ ThompsonArm ( arm_id , cnxn , type = type_ , reward = reward , active = active , customer_id = customer_id ) for arm_id , type_ , reward , active in arms ] get_best_arm ( information = None ) Samples the best arm Parameters: information ( str , default: None ) \u2013 Information provided by the customer to be stored without structure. Defaults to None. Returns: dict ( dict ) \u2013 serve Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def get_best_arm ( self , information : str = None ) -> dict : \"\"\"Samples the best arm Args: information (str, optional): Information provided by the customer to be stored without structure. Defaults to None. Returns: dict: serve \"\"\" j = np . argmax ([ arm . pull () for arm in self . arms ]) best_arm = self . arms [ j ] serve = best_arm . log_sampled ( information ) return serve TS_Bernoulli.ThompsonArm Bases: ISQL_Etiquette An implementation of the Thompson Sampling algorithm arm. Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 class ThompsonArm ( ISQL_Etiquette ): \"\"\" An implementation of the Thompson Sampling algorithm arm. \"\"\" def __init__ ( self , id : int , cnxn : sqlite3 . Connection , ** kwargs ): \"\"\"Constructor for the arm. Args: id (int): arm_id cnxn (sqlite3.Connection): sqlite3.connection Raises: ValueError: provide `type` and `reward` to create entry in DimArm if none exists ValueError: provide `customer_id` to create entry in AggregateResult if none exists \"\"\" super () . __init__ () self . cnxn = cnxn self . id = id # region checking DimArm em = f \"No arm in db with id { id } \" cur = list ( self . exec ( \"select type, reward, active from DimArm where arm_id = ?\" , ( id , ))) if len ( cur ) == 0 : if all ([ k in list ( kwargs . keys ()) for k in [ \"type\" , \"reward\" ]]): logging . warning ( em + \", attempting to create one\" ) sh = SqlHandler ( \"DimArm\" ) sh . insert_one ( arm_id = id , type = kwargs [ \"type\" ], reward = kwargs [ \"reward\" ], active = 1 ) self . type_ , self . reward , self . active = kwargs [ \"type\" ], kwargs [ \"reward\" ], 1 else : logging . error ( em ) raise ValueError ( em + \"provide `type` and `reward` to create one\" ) else : logging . info ( \"Found arm in DimArm\" ) self . type_ , self . reward , self . active = cur [ 0 ] # endregion checking DimArm # region checking AggregateResult self . sh = SqlHandler ( \"AggregateResult\" ) cur = list ( self . exec ( \"select customer_id, n_triggered, n_served, a, b, average_reward from AggregateResult where arm_id = ?\" , ( id ,))) if len ( cur ) == 0 : if \"customer_id\" in list ( kwargs . keys ()): logging . warning ( em + \", attempting to create one\" ) self . sh . insert_one ( arm_id = id , n_triggered = 0 , n_served = 0 , a = 1 , b = 1 , average_reward = 0 , customer_id = kwargs [ \"customer_id\" ]) self . n_triggered , self . n_served , self . a , self . b , self . average_reward , self . customer_id = 0 , 0 , 1 , 1 , 0 , kwargs [ \"customer_id\" ] else : logging . error ( em ) raise ValueError ( em + \"provide `customer_id` to create one\" ) else : logging . info ( \"Found arm in AggregateResult\" ) self . customer_id , self . n_triggered , self . n_served , self . a , self . b , self . average_reward = cur [ 0 ] # endregion checking AggregateResult def __repr__ ( self ) -> str : \"\"\" String representation of the arm. \"\"\" return f \"Bandit { self . id } with { self . n_triggered / self . n_served } Win Rate\" def pull ( self ) -> float : \"\"\" Pulls a random number from the beta distribution (used to determine winner while allowing for exploration) \"\"\" sample = np . random . beta ( self . a , self . b ) if self . active else 0 return sample def log_sampled ( self , information : str = None ) -> dict : \"\"\"Acknowledge the fact that this arm has been chosen by the algorithm Args: information (str, optional): Information provided by the customer to store without structure. Defaults to None. Returns: dict: serve \"\"\" self . n_served += 1 self . b = self . n_served - self . n_triggered + 1 self . sh . update_one ( self . id , n_served = self . n_served , b = self . b ) dim_date = SqlHandler ( \"DimDate\" ) date_id = dim_date . get_next_id () curr_date = datetime . now () dim_date . insert_one ( date_id = date_id , date = curr_date . strftime ( \"%Y/%m/ %d %H:%M:%S\" ), day = curr_date . day , month = curr_date . month , quarter = (( curr_date . month - 1 ) // 3 ) + 1 , year = curr_date . year ) serve_tbl = SqlHandler ( \"Serve\" ) serve_id = serve_tbl . get_next_id () serve_dict = dict ( serve_id = serve_id , date_id = date_id , customer_id = self . customer_id , arm_id = self . id , information = information , result = None ) serve_tbl . insert_one ( ** serve_dict ) return serve_dict def log_trigger ( self , serve_id : int ): \"\"\"Acknowledge the fact that this arm triggered a reward Args: serve_id (int): serve_id \"\"\" self . n_triggered += 1 self . average_reward = self . n_triggered * self . reward / self . n_served self . a += 1 self . sh . update_one ( self . id , n_triggered = self . n_triggered , average_reward = self . average_reward , a = self . a ) serve_tbl = SqlHandler ( \"Serve\" ) serve_tbl . update_one ( serve_id , result = 1 ) def change_type ( self , type = None ): \"\"\"Change the type of the arm Args: type (str, optional): Arm type. Defaults to None. \"\"\" with SqlHandler ( \"DimArm\" ) as dim_arm : arm = dim_arm . select_one ( self . id ) dim_arm . update_one ( id , type = type ) self . type_ = type def toggle_active ( self ): with SqlHandler ( \"DimArm\" ) as dim_arm : dim_arm . update_one ( self . id , active = not self . active ) self . active = not self . active return self __init__ ( id , cnxn , ** kwargs ) Constructor for the arm. Parameters: id ( int ) \u2013 arm_id cnxn ( Connection ) \u2013 sqlite3.connection Raises: ValueError \u2013 provide type and reward to create entry in DimArm if none exists ValueError \u2013 provide customer_id to create entry in AggregateResult if none exists Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def __init__ ( self , id : int , cnxn : sqlite3 . Connection , ** kwargs ): \"\"\"Constructor for the arm. Args: id (int): arm_id cnxn (sqlite3.Connection): sqlite3.connection Raises: ValueError: provide `type` and `reward` to create entry in DimArm if none exists ValueError: provide `customer_id` to create entry in AggregateResult if none exists \"\"\" super () . __init__ () self . cnxn = cnxn self . id = id # region checking DimArm em = f \"No arm in db with id { id } \" cur = list ( self . exec ( \"select type, reward, active from DimArm where arm_id = ?\" , ( id , ))) if len ( cur ) == 0 : if all ([ k in list ( kwargs . keys ()) for k in [ \"type\" , \"reward\" ]]): logging . warning ( em + \", attempting to create one\" ) sh = SqlHandler ( \"DimArm\" ) sh . insert_one ( arm_id = id , type = kwargs [ \"type\" ], reward = kwargs [ \"reward\" ], active = 1 ) self . type_ , self . reward , self . active = kwargs [ \"type\" ], kwargs [ \"reward\" ], 1 else : logging . error ( em ) raise ValueError ( em + \"provide `type` and `reward` to create one\" ) else : logging . info ( \"Found arm in DimArm\" ) self . type_ , self . reward , self . active = cur [ 0 ] # endregion checking DimArm # region checking AggregateResult self . sh = SqlHandler ( \"AggregateResult\" ) cur = list ( self . exec ( \"select customer_id, n_triggered, n_served, a, b, average_reward from AggregateResult where arm_id = ?\" , ( id ,))) if len ( cur ) == 0 : if \"customer_id\" in list ( kwargs . keys ()): logging . warning ( em + \", attempting to create one\" ) self . sh . insert_one ( arm_id = id , n_triggered = 0 , n_served = 0 , a = 1 , b = 1 , average_reward = 0 , customer_id = kwargs [ \"customer_id\" ]) self . n_triggered , self . n_served , self . a , self . b , self . average_reward , self . customer_id = 0 , 0 , 1 , 1 , 0 , kwargs [ \"customer_id\" ] else : logging . error ( em ) raise ValueError ( em + \"provide `customer_id` to create one\" ) else : logging . info ( \"Found arm in AggregateResult\" ) self . customer_id , self . n_triggered , self . n_served , self . a , self . b , self . average_reward = cur [ 0 ] __repr__ () String representation of the arm. Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 85 86 87 88 89 def __repr__ ( self ) -> str : \"\"\" String representation of the arm. \"\"\" return f \"Bandit { self . id } with { self . n_triggered / self . n_served } Win Rate\" change_type ( type = None ) Change the type of the arm Parameters: type ( str , default: None ) \u2013 Arm type. Defaults to None. Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 151 152 153 154 155 156 157 158 159 160 161 def change_type ( self , type = None ): \"\"\"Change the type of the arm Args: type (str, optional): Arm type. Defaults to None. \"\"\" with SqlHandler ( \"DimArm\" ) as dim_arm : arm = dim_arm . select_one ( self . id ) dim_arm . update_one ( id , type = type ) self . type_ = type log_sampled ( information = None ) Acknowledge the fact that this arm has been chosen by the algorithm Parameters: information ( str , default: None ) \u2013 Information provided by the customer to store without structure. Defaults to None. Returns: dict ( dict ) \u2013 serve Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def log_sampled ( self , information : str = None ) -> dict : \"\"\"Acknowledge the fact that this arm has been chosen by the algorithm Args: information (str, optional): Information provided by the customer to store without structure. Defaults to None. Returns: dict: serve \"\"\" self . n_served += 1 self . b = self . n_served - self . n_triggered + 1 self . sh . update_one ( self . id , n_served = self . n_served , b = self . b ) dim_date = SqlHandler ( \"DimDate\" ) date_id = dim_date . get_next_id () curr_date = datetime . now () dim_date . insert_one ( date_id = date_id , date = curr_date . strftime ( \"%Y/%m/ %d %H:%M:%S\" ), day = curr_date . day , month = curr_date . month , quarter = (( curr_date . month - 1 ) // 3 ) + 1 , year = curr_date . year ) serve_tbl = SqlHandler ( \"Serve\" ) serve_id = serve_tbl . get_next_id () serve_dict = dict ( serve_id = serve_id , date_id = date_id , customer_id = self . customer_id , arm_id = self . id , information = information , result = None ) serve_tbl . insert_one ( ** serve_dict ) return serve_dict log_trigger ( serve_id ) Acknowledge the fact that this arm triggered a reward Parameters: serve_id ( int ) \u2013 serve_id Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def log_trigger ( self , serve_id : int ): \"\"\"Acknowledge the fact that this arm triggered a reward Args: serve_id (int): serve_id \"\"\" self . n_triggered += 1 self . average_reward = self . n_triggered * self . reward / self . n_served self . a += 1 self . sh . update_one ( self . id , n_triggered = self . n_triggered , average_reward = self . average_reward , a = self . a ) serve_tbl = SqlHandler ( \"Serve\" ) serve_tbl . update_one ( serve_id , result = 1 ) pull () Pulls a random number from the beta distribution (used to determine winner while allowing for exploration) Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 92 93 94 95 96 97 def pull ( self ) -> float : \"\"\" Pulls a random number from the beta distribution (used to determine winner while allowing for exploration) \"\"\" sample = np . random . beta ( self . a , self . b ) if self . active else 0 return sample","title":"bayesian_ab_testing.models"},{"location":"models/#bayesian_ab_testingmodels","text":"","title":"bayesian_ab_testing.models"},{"location":"models/#bayesian_ab_testing.models.TS_Bernoulli.ThompsonAlgo.__init__","text":"Constructor that initializes the thompson algorithm Parameters: cnxn ( Connection ) \u2013 Connection to db customer_id ( int ) \u2013 customer_id Raises: ValueError \u2013 The customer has no active arms Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def __init__ ( self , cnxn : sqlite3 . Connection , customer_id : int ): \"\"\"Constructor that initializes the thompson algorithm Args: cnxn (sqlite3.Connection): Connection to db customer_id (int): customer_id Raises: ValueError: The customer has no active arms \"\"\" self . cnxn = cnxn self . customer_id = customer_id arms = list ( self . exec ( \"select arm_id, type, reward, active from DimArm where arm_id in (select arm_id from AggregateResult where customer_id = ?)\" , ( customer_id ,) )) if len ([ i for i in arms if i [ - 1 ]]) == 0 : logging . error (( em := \"The customer has no active arms\" )) raise ValueError ( em ) self . arms = [ ThompsonArm ( arm_id , cnxn , type = type_ , reward = reward , active = active , customer_id = customer_id ) for arm_id , type_ , reward , active in arms ]","title":"__init__()"},{"location":"models/#bayesian_ab_testing.models.TS_Bernoulli.ThompsonAlgo.get_best_arm","text":"Samples the best arm Parameters: information ( str , default: None ) \u2013 Information provided by the customer to be stored without structure. Defaults to None. Returns: dict ( dict ) \u2013 serve Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def get_best_arm ( self , information : str = None ) -> dict : \"\"\"Samples the best arm Args: information (str, optional): Information provided by the customer to be stored without structure. Defaults to None. Returns: dict: serve \"\"\" j = np . argmax ([ arm . pull () for arm in self . arms ]) best_arm = self . arms [ j ] serve = best_arm . log_sampled ( information ) return serve","title":"get_best_arm()"},{"location":"models/#bayesian_ab_testing.models.TS_Bernoulli.ThompsonArm.__init__","text":"Constructor for the arm. Parameters: id ( int ) \u2013 arm_id cnxn ( Connection ) \u2013 sqlite3.connection Raises: ValueError \u2013 provide type and reward to create entry in DimArm if none exists ValueError \u2013 provide customer_id to create entry in AggregateResult if none exists Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def __init__ ( self , id : int , cnxn : sqlite3 . Connection , ** kwargs ): \"\"\"Constructor for the arm. Args: id (int): arm_id cnxn (sqlite3.Connection): sqlite3.connection Raises: ValueError: provide `type` and `reward` to create entry in DimArm if none exists ValueError: provide `customer_id` to create entry in AggregateResult if none exists \"\"\" super () . __init__ () self . cnxn = cnxn self . id = id # region checking DimArm em = f \"No arm in db with id { id } \" cur = list ( self . exec ( \"select type, reward, active from DimArm where arm_id = ?\" , ( id , ))) if len ( cur ) == 0 : if all ([ k in list ( kwargs . keys ()) for k in [ \"type\" , \"reward\" ]]): logging . warning ( em + \", attempting to create one\" ) sh = SqlHandler ( \"DimArm\" ) sh . insert_one ( arm_id = id , type = kwargs [ \"type\" ], reward = kwargs [ \"reward\" ], active = 1 ) self . type_ , self . reward , self . active = kwargs [ \"type\" ], kwargs [ \"reward\" ], 1 else : logging . error ( em ) raise ValueError ( em + \"provide `type` and `reward` to create one\" ) else : logging . info ( \"Found arm in DimArm\" ) self . type_ , self . reward , self . active = cur [ 0 ] # endregion checking DimArm # region checking AggregateResult self . sh = SqlHandler ( \"AggregateResult\" ) cur = list ( self . exec ( \"select customer_id, n_triggered, n_served, a, b, average_reward from AggregateResult where arm_id = ?\" , ( id ,))) if len ( cur ) == 0 : if \"customer_id\" in list ( kwargs . keys ()): logging . warning ( em + \", attempting to create one\" ) self . sh . insert_one ( arm_id = id , n_triggered = 0 , n_served = 0 , a = 1 , b = 1 , average_reward = 0 , customer_id = kwargs [ \"customer_id\" ]) self . n_triggered , self . n_served , self . a , self . b , self . average_reward , self . customer_id = 0 , 0 , 1 , 1 , 0 , kwargs [ \"customer_id\" ] else : logging . error ( em ) raise ValueError ( em + \"provide `customer_id` to create one\" ) else : logging . info ( \"Found arm in AggregateResult\" ) self . customer_id , self . n_triggered , self . n_served , self . a , self . b , self . average_reward = cur [ 0 ]","title":"__init__()"},{"location":"models/#bayesian_ab_testing.models.TS_Bernoulli.ThompsonArm.__repr__","text":"String representation of the arm. Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 85 86 87 88 89 def __repr__ ( self ) -> str : \"\"\" String representation of the arm. \"\"\" return f \"Bandit { self . id } with { self . n_triggered / self . n_served } Win Rate\"","title":"__repr__()"},{"location":"models/#bayesian_ab_testing.models.TS_Bernoulli.ThompsonArm.change_type","text":"Change the type of the arm Parameters: type ( str , default: None ) \u2013 Arm type. Defaults to None. Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 151 152 153 154 155 156 157 158 159 160 161 def change_type ( self , type = None ): \"\"\"Change the type of the arm Args: type (str, optional): Arm type. Defaults to None. \"\"\" with SqlHandler ( \"DimArm\" ) as dim_arm : arm = dim_arm . select_one ( self . id ) dim_arm . update_one ( id , type = type ) self . type_ = type","title":"change_type()"},{"location":"models/#bayesian_ab_testing.models.TS_Bernoulli.ThompsonArm.log_sampled","text":"Acknowledge the fact that this arm has been chosen by the algorithm Parameters: information ( str , default: None ) \u2013 Information provided by the customer to store without structure. Defaults to None. Returns: dict ( dict ) \u2013 serve Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def log_sampled ( self , information : str = None ) -> dict : \"\"\"Acknowledge the fact that this arm has been chosen by the algorithm Args: information (str, optional): Information provided by the customer to store without structure. Defaults to None. Returns: dict: serve \"\"\" self . n_served += 1 self . b = self . n_served - self . n_triggered + 1 self . sh . update_one ( self . id , n_served = self . n_served , b = self . b ) dim_date = SqlHandler ( \"DimDate\" ) date_id = dim_date . get_next_id () curr_date = datetime . now () dim_date . insert_one ( date_id = date_id , date = curr_date . strftime ( \"%Y/%m/ %d %H:%M:%S\" ), day = curr_date . day , month = curr_date . month , quarter = (( curr_date . month - 1 ) // 3 ) + 1 , year = curr_date . year ) serve_tbl = SqlHandler ( \"Serve\" ) serve_id = serve_tbl . get_next_id () serve_dict = dict ( serve_id = serve_id , date_id = date_id , customer_id = self . customer_id , arm_id = self . id , information = information , result = None ) serve_tbl . insert_one ( ** serve_dict ) return serve_dict","title":"log_sampled()"},{"location":"models/#bayesian_ab_testing.models.TS_Bernoulli.ThompsonArm.log_trigger","text":"Acknowledge the fact that this arm triggered a reward Parameters: serve_id ( int ) \u2013 serve_id Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def log_trigger ( self , serve_id : int ): \"\"\"Acknowledge the fact that this arm triggered a reward Args: serve_id (int): serve_id \"\"\" self . n_triggered += 1 self . average_reward = self . n_triggered * self . reward / self . n_served self . a += 1 self . sh . update_one ( self . id , n_triggered = self . n_triggered , average_reward = self . average_reward , a = self . a ) serve_tbl = SqlHandler ( \"Serve\" ) serve_tbl . update_one ( serve_id , result = 1 )","title":"log_trigger()"},{"location":"models/#bayesian_ab_testing.models.TS_Bernoulli.ThompsonArm.pull","text":"Pulls a random number from the beta distribution (used to determine winner while allowing for exploration) Source code in bayesian_ab_testing\\models\\TS_Bernoulli\\bernoulli_algorithm.py 92 93 94 95 96 97 def pull ( self ) -> float : \"\"\" Pulls a random number from the beta distribution (used to determine winner while allowing for exploration) \"\"\" sample = np . random . beta ( self . a , self . b ) if self . active else 0 return sample","title":"pull()"},{"location":"other/","text":"Database etiquette interface/base class ISQL_Etiquette Parent class for sql-facing classes Source code in bayesian_ab_testing\\utils.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 class ISQL_Etiquette : \"\"\"Parent class for sql-facing classes\"\"\" def __init__ ( self ): pass def chk_conn ( conn ) -> bool : \"\"\"Check if connection is still alive Args: conn (sqlite3.connection): connection Returns: bool: True if is alive, false otherwise \"\"\" try : conn . cursor () return True except Exception as ex : return False def refresh_conn ( self ): \"\"\"Make sure the connection is still alive\"\"\" if not ISQL_Etiquette . chk_conn ( self . cnxn ): self . cnxn = sqlite3 . connect ( db_path ) def exec ( self , query : str , * args , ** kwargs ) -> sqlite3 . Cursor : \"\"\"Executres a given query and commits immediately after Args: query (str): query string Returns: sqlite3.Cursor: cursor \"\"\" self . refresh_conn () cur = self . cnxn . execute ( query , * args , ** kwargs ) self . cnxn . commit () return cur def exec_many ( self , query : str , * args , ** kwargs ) -> sqlite3 . Cursor : \"\"\"Executres many queries and commits immediately after Args: query (str): query string Returns: sqlite3.Cursor: cursor \"\"\" self . refresh_conn () cur = self . cnxn . executemany ( query , * args , ** kwargs ) self . cnxn . commit () return cur chk_conn ( conn ) Check if connection is still alive Parameters: conn ( connection ) \u2013 connection Returns: bool ( bool ) \u2013 True if is alive, false otherwise Source code in bayesian_ab_testing\\utils.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def chk_conn ( conn ) -> bool : \"\"\"Check if connection is still alive Args: conn (sqlite3.connection): connection Returns: bool: True if is alive, false otherwise \"\"\" try : conn . cursor () return True except Exception as ex : return False exec ( query , * args , ** kwargs ) Executres a given query and commits immediately after Parameters: query ( str ) \u2013 query string Returns: Cursor \u2013 sqlite3.Cursor: cursor Source code in bayesian_ab_testing\\utils.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def exec ( self , query : str , * args , ** kwargs ) -> sqlite3 . Cursor : \"\"\"Executres a given query and commits immediately after Args: query (str): query string Returns: sqlite3.Cursor: cursor \"\"\" self . refresh_conn () cur = self . cnxn . execute ( query , * args , ** kwargs ) self . cnxn . commit () return cur exec_many ( query , * args , ** kwargs ) Executres many queries and commits immediately after Parameters: query ( str ) \u2013 query string Returns: Cursor \u2013 sqlite3.Cursor: cursor Source code in bayesian_ab_testing\\utils.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def exec_many ( self , query : str , * args , ** kwargs ) -> sqlite3 . Cursor : \"\"\"Executres many queries and commits immediately after Args: query (str): query string Returns: sqlite3.Cursor: cursor \"\"\" self . refresh_conn () cur = self . cnxn . executemany ( query , * args , ** kwargs ) self . cnxn . commit () return cur refresh_conn () Make sure the connection is still alive Source code in bayesian_ab_testing\\utils.py 31 32 33 34 def refresh_conn ( self ): \"\"\"Make sure the connection is still alive\"\"\" if not ISQL_Etiquette . chk_conn ( self . cnxn ): self . cnxn = sqlite3 . connect ( db_path ) Logger CustomFormatter Bases: Formatter Custom formatter for Informative Logging Source code in bayesian_ab_testing\\logger\\logger.py 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class CustomFormatter ( logging . Formatter ): \"\"\" Custom formatter for Informative Logging \"\"\" grey = \" \\x1b [38;20m\" violet = \" \\x1b [38;5;183m\" yellow = \" \\x1b [33;20m\" red = \" \\x1b [31;20m\" bold_red = \" \\x1b [31;1m\" reset = \" \\x1b [0m\" format = \" %(asctime)s - %(name)s - %(funcName)s - %(levelname)s - ( %(message)s ) - line: %(lineno)d \" FORMATS = { logging . DEBUG : grey + format + reset , logging . INFO : violet + format + reset , logging . WARNING : yellow + format + reset , logging . ERROR : red + format + reset , logging . CRITICAL : bold_red + format + reset } def format ( self , record ): \"\"\" Parameters ---------- record : takes the record Returns ------- returns formated(colored) output \"\"\" log_fmt = self . FORMATS . get ( record . levelno ) formatter = logging . Formatter ( log_fmt ) return formatter . format ( record ) format ( record ) Parameters record : takes the record Returns returns formated(colored) output Source code in bayesian_ab_testing\\logger\\logger.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def format ( self , record ): \"\"\" Parameters ---------- record : takes the record Returns ------- returns formated(colored) output \"\"\" log_fmt = self . FORMATS . get ( record . levelno ) formatter = logging . Formatter ( log_fmt ) return formatter . format ( record )","title":"Other"},{"location":"other/#bayesian_ab_testing.utils.ISQL_Etiquette.chk_conn","text":"Check if connection is still alive Parameters: conn ( connection ) \u2013 connection Returns: bool ( bool ) \u2013 True if is alive, false otherwise Source code in bayesian_ab_testing\\utils.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def chk_conn ( conn ) -> bool : \"\"\"Check if connection is still alive Args: conn (sqlite3.connection): connection Returns: bool: True if is alive, false otherwise \"\"\" try : conn . cursor () return True except Exception as ex : return False","title":"chk_conn()"},{"location":"other/#bayesian_ab_testing.utils.ISQL_Etiquette.exec","text":"Executres a given query and commits immediately after Parameters: query ( str ) \u2013 query string Returns: Cursor \u2013 sqlite3.Cursor: cursor Source code in bayesian_ab_testing\\utils.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def exec ( self , query : str , * args , ** kwargs ) -> sqlite3 . Cursor : \"\"\"Executres a given query and commits immediately after Args: query (str): query string Returns: sqlite3.Cursor: cursor \"\"\" self . refresh_conn () cur = self . cnxn . execute ( query , * args , ** kwargs ) self . cnxn . commit () return cur","title":"exec()"},{"location":"other/#bayesian_ab_testing.utils.ISQL_Etiquette.exec_many","text":"Executres many queries and commits immediately after Parameters: query ( str ) \u2013 query string Returns: Cursor \u2013 sqlite3.Cursor: cursor Source code in bayesian_ab_testing\\utils.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def exec_many ( self , query : str , * args , ** kwargs ) -> sqlite3 . Cursor : \"\"\"Executres many queries and commits immediately after Args: query (str): query string Returns: sqlite3.Cursor: cursor \"\"\" self . refresh_conn () cur = self . cnxn . executemany ( query , * args , ** kwargs ) self . cnxn . commit () return cur","title":"exec_many()"},{"location":"other/#bayesian_ab_testing.utils.ISQL_Etiquette.refresh_conn","text":"Make sure the connection is still alive Source code in bayesian_ab_testing\\utils.py 31 32 33 34 def refresh_conn ( self ): \"\"\"Make sure the connection is still alive\"\"\" if not ISQL_Etiquette . chk_conn ( self . cnxn ): self . cnxn = sqlite3 . connect ( db_path )","title":"refresh_conn()"},{"location":"other/#bayesian_ab_testing.logger.CustomFormatter.format","text":"","title":"format()"},{"location":"other/#bayesian_ab_testing.logger.CustomFormatter.format--parameters","text":"record : takes the record","title":"Parameters"},{"location":"other/#bayesian_ab_testing.logger.CustomFormatter.format--returns","text":"returns formated(colored) output Source code in bayesian_ab_testing\\logger\\logger.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def format ( self , record ): \"\"\" Parameters ---------- record : takes the record Returns ------- returns formated(colored) output \"\"\" log_fmt = self . FORMATS . get ( record . levelno ) formatter = logging . Formatter ( log_fmt ) return formatter . format ( record )","title":"Returns"}]}